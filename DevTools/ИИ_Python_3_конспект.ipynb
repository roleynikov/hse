{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yYjPce3d6j7Q",
        "u_istv_E6q-m",
        "jssBOog-6vO_",
        "Se8vzyfl60DF",
        "C51oX1qAB0tB",
        "75QYYJypEDhs",
        "1qra5SXwEHk6",
        "SnWJcOHVEKjb",
        "HGd7RYwtEOHy",
        "K9VLa3mbEU6Z",
        "i0kvJ96J5iBp",
        "QdHa8TcD_4Mf",
        "UTRirtrGFDQn",
        "nM3LWp4pGaEe",
        "sST1YJbw5h-0",
        "52pwVPJ95h0b"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. GIL (Global Interpreter Lock)"
      ],
      "metadata": {
        "id": "yYjPce3d6j7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GIL (Global Interpreter Lock)** — это механизм, используемый интерпретатором CPython для предотвращения одновременного выполнения нескольких потоков Python. Это глобальная блокировка, которая гарантирует, что в каждый момент времени только один поток выполняет байт-код Python, даже если программа имеет несколько потоков.\n",
        "\n",
        "#### Почему существует GIL?\n",
        "\n",
        "GIL упрощает реализацию интерпретатора Python, так как:\n",
        "1. Управление памятью в Python основано на автоматическом подсчете ссылок, и GIL предотвращает конфликты между потоками при изменении счетчиков ссылок.\n",
        "2. Это упрощает разработку встроенных модулей на C, так как они не требуют сложной синхронизации для безопасного доступа к данным.\n",
        "\n",
        "#### Как работает GIL?\n",
        "\n",
        "1. **Исполнение Python-кода**:\n",
        "   - GIL удерживается одним потоком во время выполнения Python-кода.\n",
        "   - Если поток выполняет I/O (например, сетевые операции), он освобождает GIL, позволяя другим потокам исполняться.\n",
        "\n",
        "2. **Планирование потоков**:\n",
        "   - Если один поток выполняет вычисления (CPU-bound), другие потоки блокируются, ожидая освобождения GIL.\n",
        "   - GIL переключается между потоками на уровне интерпретатора, что создает накладные расходы.\n",
        "   \n",
        "#### Последствия GIL\n",
        "\n",
        "1. **Ограничение многопоточности**:\n",
        "   - Даже если программа использует несколько потоков, GIL разрешает только одному потоку выполнять байт-код Python в каждый момент времени. Это приводит к тому, что CPU-bound задачи (интенсивные вычисления) не могут выполняться параллельно на нескольких ядрах.\n",
        "\n",
        "2. **Эффективная работа для I/O-bound задач**:\n",
        "   - В задачах, связанных с вводом-выводом (например, сетевые запросы, работа с файлами), потоки могут поочередно захватывать GIL, что позволяет эффективно использовать асинхронность.\n",
        "\n",
        "3. **Примеры проблем GIL**:\n",
        "   - Если в программе используется несколько потоков для сложных вычислений, она может работать медленнее, чем с одним потоком, так как потоки будут конкурировать за GIL."
      ],
      "metadata": {
        "id": "NxpoTZyR8Fxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Пример демонстрации GIL"
      ],
      "metadata": {
        "id": "oehp0jK-8exH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "def cpu_task():\n",
        "    total = 0\n",
        "    for i in range(10**7):\n",
        "        total += i\n",
        "\n",
        "threads = [threading.Thread(target=cpu_task) for _ in range(4)]\n"
      ],
      "metadata": {
        "id": "39K82Y8S8Tb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "for t in threads:\n",
        "    t.start()\n",
        "for t in threads:\n",
        "    t.join()\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Время выполнения с потоками: {end - start:.2f} секунд\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp9_14eK8FVD",
        "outputId": "4444370d-081c-4b7a-aad4-38922f1fbe22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время выполнения с потоками: 2.64 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "cpu_task()\n",
        "end = time.time()\n",
        "print(f\"Время выполнения без потоков: {end - start:.2f} секунд\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFl5K2be8Jue",
        "outputId": "87a07e12-c723-4e0d-c42b-27a65ff3489a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время выполнения без потоков: 0.68 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Как обойти GIL?\n",
        "\n",
        "1. **Использование процессов (`multiprocessing`)**:\n",
        "   - Процессы создают независимые экземпляры интерпретатора Python, что позволяет выполнять задачи параллельно на разных ядрах процессора.\n",
        "\n",
        "2. **Использование встроенных модулей на C**:\n",
        "   - Некоторые модули, такие как `numpy`, освобождают GIL для выполнения своих вычислений.\n"
      ],
      "metadata": {
        "id": "z_reb8M96fzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Потоки"
      ],
      "metadata": {
        "id": "u_istv_E6q-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Потоки (threads) — это **легковесные единицы выполнения** внутри одного процесса. Все потоки в одном процессе разделяют общую память, что позволяет им быстро обмениваться данными, но также требует синхронизации.\n",
        "\n",
        "**Преимущества потоков**:\n",
        "- Быстрая передача данных между потоками, так как они используют общую память.\n",
        "- Подходят для задач, связанных с I/O, например сетевых запросов, работы с файлами.\n",
        "\n",
        "**Недостатки потоков**:\n",
        "- GIL ограничивает параллельное выполнение потоков для CPU-bound задач.\n",
        "- Риск ошибок из-за конкурентного доступа к общей памяти (race conditions).\n"
      ],
      "metadata": {
        "id": "GJJ61HaW6p6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Пример использования потоков:"
      ],
      "metadata": {
        "id": "AekoSPG38xAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "def print_task(n):\n",
        "    print(f\"Поток {n} начал выполнение\")\n",
        "    time.sleep(1)\n",
        "    print(f\"Поток {n} завершился\")\n",
        "\n",
        "threads = [threading.Thread(target=print_task, args=(i,)) for i in range(3)]\n",
        "for t in threads:\n",
        "    t.start()\n",
        "for t in threads:\n",
        "    t.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G-lq6FH8xZo",
        "outputId": "ac2718bf-5acd-4e36-99e5-832ad8d7fdb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Поток 0 начал выполнение\n",
            "Поток 1 начал выполнение\n",
            "Поток 2 начал выполнение\n",
            "Поток 0 завершился\n",
            "Поток 1 завершился\n",
            "Поток 2 завершился\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Процессы"
      ],
      "metadata": {
        "id": "jssBOog-6vO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Процессы (processes) — это **независимые экземпляры программы**, каждый из которых имеет свою память. В Python процессы создаются с помощью модуля `multiprocessing`.\n",
        "\n",
        "**Преимущества процессов**:\n",
        "- Параллельное выполнение задач на нескольких ядрах процессора.\n",
        "- Отсутствие GIL, так как каждый процесс работает в своем интерпретаторе.\n",
        "\n",
        "**Недостатки процессов**:\n",
        "- Более высокая стоимость создания и управления процессами по сравнению с потоками.\n",
        "- Необходимость обмена данными между процессами через очереди или каналы.\n"
      ],
      "metadata": {
        "id": "-qxegsGw88NE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Пример использования процессов:"
      ],
      "metadata": {
        "id": "XNyK7KIg88I9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process\n",
        "\n",
        "def print_task(n):\n",
        "    print(f\"Процесс {n} начал выполнение\")\n",
        "    time.sleep(1)\n",
        "    print(f\"Процесс {n} завершился\")\n",
        "\n",
        "processes = [Process(target=print_task, args=(i,)) for i in range(3)]\n",
        "for p in processes:\n",
        "    p.start()\n",
        "for p in processes:\n",
        "    p.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t15EO3B8715",
        "outputId": "cdfa74d5-5ffd-4518-8e96-ab21ab911eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Процесс 0 начал выполнение\n",
            "Процесс 1 начал выполнениеПроцесс 2 начал выполнение\n",
            "\n",
            "Процесс 0 завершился\n",
            "Процесс 2 завершился\n",
            "Процесс 1 завершился\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Основы синхронизации"
      ],
      "metadata": {
        "id": "Se8vzyfl60DF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Когда несколько потоков или процессов работают с общими ресурсами, может возникнуть **конкуренция** за эти ресурсы. Для предотвращения конфликтов используются механизмы синхронизации.\n",
        "\n",
        "#### Проблема конкурентного доступа (race condition)\n",
        "\n",
        "Конкурентный доступ возникает, когда несколько потоков одновременно изменяют общую переменную, что может приводить к непредсказуемым результатам.\n",
        "\n",
        "**Пример race condition**:"
      ],
      "metadata": {
        "id": "V6wkFIbi9ISp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "def increment(counter, lock):\n",
        "    for _ in range(10**6):\n",
        "        # Uncomment the lock.acquire() and lock.release() lines to fix the race condition\n",
        "        # lock.acquire()\n",
        "        counter.value += 1\n",
        "        # lock.release()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Shared memory counter\n",
        "    counter = multiprocessing.Value('i', 0)  # 'i' indicates an integer\n",
        "    lock = multiprocessing.Lock()  # Uncomment to synchronize processes\n",
        "\n",
        "    processes = [multiprocessing.Process(target=increment, args=(counter, lock)) for _ in range(2)]\n",
        "\n",
        "    for p in processes:\n",
        "        p.start()\n",
        "    for p in processes:\n",
        "        p.join()\n",
        "\n",
        "    print(f\"Result: {counter.value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79bpun629IkJ",
        "outputId": "9253904b-47e9-411e-acaf-7a99b5e6e07e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: 1222745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "counter = 0\n",
        "\n",
        "def increment():\n",
        "    global counter\n",
        "    for _ in range(10**6):\n",
        "        temp = counter\n",
        "        temp += 1\n",
        "        counter = temp\n",
        "\n",
        "threads = [threading.Thread(target=increment) for _ in range(2)]\n",
        "for t in threads:\n",
        "    t.start()\n",
        "for t in threads:\n",
        "    t.join()\n",
        "\n",
        "print(f\"Result: {counter}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQOLC17D-Uq_",
        "outputId": "1cc01af1-6281-457b-f52c-f598b05df686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: 2000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Параллелизм с `concurrent.futures`\n",
        "\n",
        "Что происходит внутри?\n",
        "\n",
        "1. **Параллелизм с использованием процессов**:\n",
        "   - `ProcessPoolExecutor` создаёт несколько независимых процессов.\n",
        "   - Каждый процесс получает функцию `process_row` и данные для обработки.\n",
        "   - Процессы изолированы, поэтому данные передаются между процессами через механизм сериализации (например, с использованием `pickle`).\n",
        "\n",
        "2. **Преимущество параллелизма**:\n",
        "   - Каждый процесс работает независимо от других, поэтому обработка больших данных может быть ускорена за счёт параллельного выполнения.\n",
        "\n",
        "3. **Ограничения**:\n",
        "   - Есть накладные расходы на передачу данных между процессами (сериализация/десериализация).\n",
        "   - Подходит для задач, где вычисления являются узким местом (например, обработка больших массивов данных или интенсивные вычисления).\n",
        "\n",
        "Этот метод часто используется для обработки данных, машинного обучения или выполнения задач, требующих значительных вычислительных ресурсов.\n",
        "\n"
      ],
      "metadata": {
        "id": "amzXxCpn6Tlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ProcessPoolExecutor\n",
        "\n",
        "def process_row(row):\n",
        "    return row['a'] + row['b']\n",
        "\n",
        "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\n",
        "with ProcessPoolExecutor() as executor:\n",
        "    results = list(executor.map(process_row, df.to_dict(orient='records')))\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9193YRnI_WmS",
        "outputId": "3c7317ea-4501-4b59-ff8a-86c665ebe4be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 7, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Механизмы синхронизации в Python"
      ],
      "metadata": {
        "id": "C51oX1qAB0tB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. **Мьютексы (Locks)**"
      ],
      "metadata": {
        "id": "75QYYJypEDhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мьютекс используется, чтобы гарантировать, что только один поток выполняет определенный участок кода.\n",
        "\n",
        "   - Только один поток или процесс может удерживать мьютекс в данный момент.\n",
        "   - Используется для защиты критических секций кода, где осуществляется доступ к общим данным."
      ],
      "metadata": {
        "id": "vx7zYXJcCCZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "def increment(counter, lock):\n",
        "    for _ in range(10**6):\n",
        "        with lock:\n",
        "            counter.value += 1\n",
        "\n",
        "counter = multiprocessing.Value('i', 0)\n",
        "lock = multiprocessing.Lock()\n",
        "\n",
        "processes = [multiprocessing.Process(target=increment, args=(counter, lock)) for _ in range(4)]\n",
        "\n",
        "for p in processes:\n",
        "    p.start()\n",
        "\n",
        "for p in processes:\n",
        "    p.join()\n",
        "\n",
        "print(f\"Значение counter: {counter.value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd7Gb067CEOI",
        "outputId": "f44bafc9-a326-4273-8f09-2e012219a9cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Значение counter: 4000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Без `lock` результат мог бы быть меньше ожидаемого из-за состояния гонки.\n",
        "- Мьютекс гарантирует, что `counter` изменяется только одним потоком в каждый момент времени.\n",
        "\n",
        "Потенциальные проблемы:\n",
        "- **Deadlock (взаимная блокировка)**: Если мьютекс не освобождается, программа может зависнуть.\n"
      ],
      "metadata": {
        "id": "_s0_8GaQCABA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. **События (Events)**\n"
      ],
      "metadata": {
        "id": "1qra5SXwEHk6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "События используются для координации выполнения потоков. Один поток устанавливает событие, а другой ожидает его."
      ],
      "metadata": {
        "id": "OD6rZcF5B_-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "event = threading.Event()\n",
        "\n",
        "def waiter():\n",
        "    print(\"Жду события...\")\n",
        "    event.wait()  # Блокируем поток, пока событие не установлено\n",
        "    print(\"Событие произошло!\")\n",
        "\n",
        "def setter():\n",
        "    print(\"Готовлюсь установить событие...\")\n",
        "    event.set()  # Устанавливаем событие, разблокируя ожидающий поток\n",
        "\n",
        "thread1 = threading.Thread(target=waiter)\n",
        "thread2 = threading.Thread(target=setter)\n",
        "\n",
        "thread1.start()\n",
        "thread2.start()\n",
        "\n",
        "thread1.join()\n",
        "thread2.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QnnxuMACnrG",
        "outputId": "7f072faf-d199-468b-f78f-0ff3e9765590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Жду события...\n",
            "Готовлюсь установить событие...\n",
            "Событие произошло!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `event.wait()` блокирует поток, пока событие не установлено.\n",
        "- `event.set()` разблокирует все потоки, ожидающие этого события.\n",
        "\n",
        "Применение:\n",
        "- Координация потоков для выполнения задач в определенном порядке.\n"
      ],
      "metadata": {
        "id": "YZhEBO9zB_7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. **Очереди (Queues)**"
      ],
      "metadata": {
        "id": "SnWJcOHVEKjb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Очереди используются для передачи данных между потоками или процессами. Они автоматически синхронизированы, поэтому вам не нужно использовать мьютексы."
      ],
      "metadata": {
        "id": "MNQpslbfCxF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "from queue import Queue\n",
        "\n",
        "queue = Queue()\n",
        "\n",
        "def producer():\n",
        "    for i in range(5):\n",
        "        queue.put(i)\n",
        "        print(f\"Производитель добавил: {i}\")\n",
        "\n",
        "def consumer():\n",
        "    while not queue.empty():\n",
        "        item = queue.get()\n",
        "        print(f\"Потребитель взял: {item}\")\n",
        "        queue.task_done()\n",
        "\n",
        "producer_thread = threading.Thread(target=producer)\n",
        "consumer_thread = threading.Thread(target=consumer)\n",
        "\n",
        "producer_thread.start()\n",
        "producer_thread.join()\n",
        "\n",
        "consumer_thread.start()\n",
        "consumer_thread.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id1F2PtJCzLo",
        "outputId": "b225652e-ae43-4aa3-a686-ff396fa8871b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Производитель добавил: 0\n",
            "Производитель добавил: 1\n",
            "Производитель добавил: 2\n",
            "Производитель добавил: 3\n",
            "Производитель добавил: 4\n",
            "Потребитель взял: 0\n",
            "Потребитель взял: 1\n",
            "Потребитель взял: 2\n",
            "Потребитель взял: 3\n",
            "Потребитель взял: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Производитель добавляет элементы в очередь.\n",
        "- Потребитель извлекает элементы из очереди.\n",
        "- Очередь обеспечивает автоматическую синхронизацию.\n"
      ],
      "metadata": {
        "id": "xWuXe9cPCw82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. **Семафоры (Semaphores)**"
      ],
      "metadata": {
        "id": "HGd7RYwtEOHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Семафор используется для ограничения количества потоков, которые могут одновременно выполнять код.\n",
        "\n",
        "   - Используется для управления доступом к ресурсам, которые могут быть использованы одновременно несколькими потоками."
      ],
      "metadata": {
        "id": "8j3Kflo-Cw5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "semaphore = multiprocessing.Semaphore(2)\n",
        "\n",
        "def task(n):\n",
        "    with semaphore:  # Гарантируем, что только 2 процесса выполняют эту секцию\n",
        "        print(f\"Процесс {n} начал выполнение\")\n",
        "        time.sleep(1)\n",
        "        print(f\"Процесс {n} завершил выполнение\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    processes = [multiprocessing.Process(target=task, args=(i,)) for i in range(5)]\n",
        "\n",
        "    for p in processes:\n",
        "        p.start()\n",
        "    for p in processes:\n",
        "        p.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsr2_RQVDE2D",
        "outputId": "7920e9dc-af02-4843-fc61-969a7753de4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Процесс 0 начал выполнение\n",
            "Процесс 1 начал выполнение\n",
            "Процесс 0 завершил выполнение\n",
            "Процесс 1 завершил выполнениеПроцесс 2 начал выполнение\n",
            "\n",
            "Процесс 3 начал выполнение\n",
            "Процесс 2 завершил выполнение\n",
            "Процесс 4 начал выполнениеПроцесс 3 завершил выполнение\n",
            "\n",
            "Процесс 4 завершил выполнение\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "semaphore = threading.Semaphore(2)  # Семафор больше не используется\n",
        "\n",
        "def task(n):\n",
        "    # Выполнение без ограничения\n",
        "    print(f\"Поток {n} начал выполнение\")\n",
        "    time.sleep(1)\n",
        "    print(f\"Поток {n} завершил выполнение\")\n",
        "\n",
        "threads = [threading.Thread(target=task, args=(i,)) for i in range(5)]\n",
        "\n",
        "for t in threads:\n",
        "    t.start()\n",
        "for t in threads:\n",
        "    t.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiRN3AaQDZo_",
        "outputId": "3b80c10c-81a0-459f-d674-0e61c4490322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Поток 0 начал выполнениеПоток 1 начал выполнение\n",
            "Поток 2 начал выполнение\n",
            "\n",
            "Поток 3 начал выполнение\n",
            "Поток 4 начал выполнение\n",
            "Поток 0 завершил выполнениеПоток 1 завершил выполнение\n",
            "\n",
            "Поток 3 завершил выполнение\n",
            "Поток 2 завершил выполнение\n",
            "Поток 4 завершил выполнение\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Одновременно выполняются только 2 потока.\n",
        "- Остальные потоки ждут, пока один из занятых потоков освободит семафор.\n",
        "\n",
        "Применение:\n",
        "- Управление доступом к ресурсам с ограниченной емкостью (например, подключения к базе данных)."
      ],
      "metadata": {
        "id": "FOkfI_brB_3d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. **Барьеры (Barriers)**"
      ],
      "metadata": {
        "id": "K9VLa3mbEU6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Барьер заставляет несколько потоков синхронизироваться в одной точке, прежде чем они продолжат выполнение"
      ],
      "metadata": {
        "id": "uTcUW8twDl8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "barrier = threading.Barrier(3)\n",
        "\n",
        "def worker(n):\n",
        "    print(f\"Поток {n} достиг барьера\")\n",
        "    barrier.wait()  # Ожидание других потоков\n",
        "    print(f\"Поток {n} продолжил выполнение\")\n",
        "\n",
        "threads = [threading.Thread(target=worker, args=(i,)) for i in range(3)]\n",
        "\n",
        "for t in threads:\n",
        "    t.start()\n",
        "for t in threads:\n",
        "    t.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4i1vu1C-DtET",
        "outputId": "b92efe34-8529-429c-e5ca-3cc57e94f801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Поток 0 достиг барьера\n",
            "Поток 1 достиг барьера\n",
            "Поток 2 достиг барьера\n",
            "Поток 2 продолжил выполнениеПоток 1 продолжил выполнениеПоток 0 продолжил выполнение\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Потоки блокируются на вызове `barrier.wait()`, пока все 3 потока не достигнут этой точки.\n"
      ],
      "metadata": {
        "id": "mcJHkcgzDwG1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Сравнение механизмов синхронизации\n",
        "\n",
        "| Механизм       | Применение                                     | Особенности                                                      |\n",
        "|----------------|------------------------------------------------|------------------------------------------------------------------|\n",
        "| **Мьютекс**    | Защита критических секций                     | Простое управление, риск deadlock                               |\n",
        "| **Событие**    | Координация потоков                           | Удобен для управления зависимыми задачами                       |\n",
        "| **Очередь**    | Безопасный обмен данными                      | Простота использования, автоматическая синхронизация            |\n",
        "| **Семафор**    | Ограничение доступа к ресурсу                 | Контроль количества потоков/процессов, использующих ресурс      |\n",
        "| **Барьер**     | Синхронизация нескольких потоков              | Блокировка до завершения всех задач                             |"
      ],
      "metadata": {
        "id": "Dm_rU_HUDz6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Основные различия между многопоточностью и асинхронностью\n"
      ],
      "metadata": {
        "id": "i0kvJ96J5iBp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Основные различия между многопоточностью и асинхронностью\n",
        "\n",
        "| **Характеристика**           | **Многопоточность**                      | **Асинхронность**                      |\n",
        "|------------------------------|-----------------------------------------|----------------------------------------|\n",
        "| **Исполнение**               | Выполняет задачи в параллельных потоках | Одна главная петля, переключающаяся между задачами |\n",
        "| **Подходит для задач**        | I/O-bound и CPU-bound                   | I/O-bound                              |\n",
        "| **Ресурсоемкость**            | Занимает больше памяти на потоки        | Легковесный механизм                   |\n",
        "| **Управление задачами**       | Зависит от ОС                          | Управляется библиотекой (например, `asyncio`) |\n",
        "| **Проблемы с синхронизацией** | Необходимость мьютексов, deadlock       | Не требуется, так как задачи выполняются последовательно |\n",
        "| **Производительность при I/O**| Высокая (для блокирующего ввода-вывода)| Очень высокая (для неблокирующего ввода-вывода) |\n",
        "\n",
        "\n",
        "### Когда использовать многопоточность?\n",
        "\n",
        "**Многопоточность подходит, если:**\n",
        "\n",
        "1. **Задачи связаны с блокирующим I/O (например, чтение файлов или блокирующие API)**:\n",
        "   - Если задачи используют библиотеку, которая не поддерживает асинхронность (например, `requests` для сетевых запросов), потоки могут быть удобным выбором.\n",
        "\n",
        "2. **Программа сочетает I/O и CPU-bound задачи**:\n",
        "   - Например, после загрузки данных из API нужно выполнить тяжелую обработку. Потоки могут параллельно загружать данные и обрабатывать их.\n",
        "\n",
        "3. **Код должен работать с существующими библиотеками**:\n",
        "   - Если вы не можете изменить существующий код для поддержки асинхронности, потоки станут более естественным выбором.\n",
        "\n",
        "#### Пример: Многопоточность для чтения файлов\n",
        "\n",
        "```python\n",
        "import threading\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        content = f.read()\n",
        "    print(f\"Файл {filename} прочитан, {len(content)} символов\")\n",
        "\n",
        "files = ['file1.txt', 'file2.txt', 'file3.txt']\n",
        "threads = [threading.Thread(target=read_file, args=(file,)) for file in files]\n",
        "\n",
        "for thread in threads:\n",
        "    thread.start()\n",
        "for thread in threads:\n",
        "    thread.join()\n",
        "```\n",
        "\n",
        "**Почему потоки работают здесь хорошо?**\n",
        "- Каждое чтение блокирует поток, но другой поток может выполнять свою работу, пока первый ждет завершения.\n",
        "\n",
        "#### Пример: Многопоточность для сетевых запросов (с `requests`)\n",
        "\n",
        "```python\n",
        "import threading\n",
        "import requests\n",
        "\n",
        "def fetch_data(url):\n",
        "    response = requests.get(url)\n",
        "    print(f\"Получены данные с {url}: {len(response.text)} символов\")\n",
        "\n",
        "urls = ['https://example.com', 'https://httpbin.org/get', 'https://api.github.com']\n",
        "threads = [threading.Thread(target=fetch_data, args=(url,)) for url in urls]\n",
        "\n",
        "for thread in threads:\n",
        "    thread.start()\n",
        "for thread in threads:\n",
        "    thread.join()\n",
        "```\n",
        "\n",
        "**Почему здесь многопоточность полезна?**\n",
        "- `requests` — это блокирующая библиотека. Потоки позволяют выполнять запросы одновременно.\n",
        "\n",
        "---\n",
        "\n",
        "### Когда использовать асинхронность?\n",
        "\n",
        "**Асинхронность подходит, если:**\n",
        "\n",
        "1. **Работа с I/O-bound задачами с поддержкой асинхронных библиотек**:\n",
        "   - Например, `aiohttp` для сетевых запросов или асинхронные операции с базами данных.\n",
        "\n",
        "2. **Высокая нагрузка**:\n",
        "   - Асинхронность позволяет обрабатывать тысячи запросов одновременно с минимальными затратами памяти.\n",
        "\n",
        "3. **Легковесность и простота масштабирования**:\n",
        "   - Асинхронность требует меньше ресурсов по сравнению с потоками, что делает её более подходящей для масштабируемых приложений.\n",
        "\n",
        "#### Пример: Асинхронное чтение файлов\n",
        "\n",
        "В стандартной библиотеке Python нет встроенного асинхронного чтения файлов, но можно использовать библиотеку `aiofiles`:\n",
        "\n",
        "```python\n",
        "import asyncio\n",
        "import aiofiles\n",
        "\n",
        "async def read_file(filename):\n",
        "    async with aiofiles.open(filename, 'r') as f:\n",
        "        content = await f.read()\n",
        "    print(f\"Файл {filename} прочитан, {len(content)} символов\")\n",
        "\n",
        "async def main():\n",
        "    files = ['file1.txt', 'file2.txt', 'file3.txt']\n",
        "    tasks = [read_file(file) for file in files]\n",
        "    await asyncio.gather(*tasks)\n",
        "\n",
        "asyncio.run(main())\n",
        "```\n",
        "\n",
        "**Почему асинхронность здесь полезна?**\n",
        "- Если чтение файла включает I/O-задержки (например, чтение из сетевых дисков), асинхронность позволяет обрабатывать несколько файлов одновременно.\n",
        "\n",
        "#### Пример: Асинхронные сетевые запросы (с `aiohttp`)\n",
        "\n",
        "```python\n",
        "import aiohttp\n",
        "import asyncio\n",
        "\n",
        "async def fetch_data(url):\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        async with session.get(url) as response:\n",
        "            content = await response.text()\n",
        "            print(f\"Получены данные с {url}: {len(content)} символов\")\n",
        "\n",
        "async def main():\n",
        "    urls = ['https://example.com', 'https://httpbin.org/get', 'https://api.github.com']\n",
        "    tasks = [fetch_data(url) for url in urls]\n",
        "    await asyncio.gather(*tasks)\n",
        "\n",
        "asyncio.run(main())\n",
        "```\n",
        "\n",
        "**Почему здесь асинхронность лучше?**\n",
        "- `aiohttp` позволяет выполнять запросы неблокирующим образом, что делает асинхронность идеальной для работы с большим количеством URL.\n",
        "\n",
        "---\n",
        "\n",
        "### Что выбрать?\n",
        "\n",
        "| Ситуация                              | Выбор               | Почему                                                   |\n",
        "|---------------------------------------|---------------------|----------------------------------------------------------|\n",
        "| Работа с I/O-bound задачами           | Асинхронность       | Легковеснее и эффективнее для большого количества задач. |\n",
        "| Работа с блокирующими библиотеками    | Многопоточность     | Потоки позволяют обрабатывать блокирующий I/O параллельно. |\n",
        "| Смешанные задачи (I/O + CPU)          | Комбинирование      | Потоки или процессы для CPU, асинхронность для I/O.      |\n",
        "| Высокая нагрузка (тысячи задач)       | Асинхронность       | Асинхронность эффективнее при масштабировании.           |\n",
        "\n",
        "---\n",
        "\n",
        "### Выводы\n",
        "\n",
        "1. **Асинхронность**:\n",
        "   - Лучшая альтернатива для **I/O-bound задач**, когда используются асинхронные библиотеки.\n",
        "   - Особенно эффективна для приложений с высокой нагрузкой.\n",
        "\n",
        "2. **Многопоточность**:\n",
        "   - Хороший выбор для работы с **блокирующими библиотеками** или при необходимости смешивать I/O и CPU-bound задачи.\n",
        "\n",
        "3. Если библиотека поддерживает асинхронность (например, `aiohttp` вместо `requests`), используйте асинхронный подход. Если нет, многопоточность — ваш выбор."
      ],
      "metadata": {
        "id": "7e-pAwnUDl3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Реальные примеры использования потоков и процессов с кодом\n",
        "\n",
        "Давайте рассмотрим **реальные задачи**, которые можно ускорить с помощью потоков или процессов, а также разберем случаи, где такие подходы не дают ощутимого выигрыша. Мы будем рассматривать примеры из **реальной практики**: обработка файлов, сетевые запросы, интенсивные вычисления и взаимодействие с базами данных.\n"
      ],
      "metadata": {
        "id": "QdHa8TcD_4Mf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Пример 1: Обработка множества текстовых файлов\n",
        "\n",
        "**Задача**: У нас есть множество текстовых файлов, которые нужно прочитать, подсчитать количество слов и записать результаты в новый файл. Файлы не зависят друг от друга, так что можно обрабатывать их параллельно.\n",
        "\n",
        "#### Подход с потоками (I/O-bound)\n",
        "\n",
        "```python\n",
        "import threading\n",
        "import os\n",
        "\n",
        "def count_words_in_file(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        content = f.read()\n",
        "    word_count = len(content.split())\n",
        "    print(f\"Файл {filename}: {word_count} слов\")\n",
        "\n",
        "def process_files_threading(file_list):\n",
        "    threads = [threading.Thread(target=count_words_in_file, args=(file,)) for file in file_list]\n",
        "    for thread in threads:\n",
        "        thread.start()\n",
        "    for thread in threads:\n",
        "        thread.join()\n",
        "\n",
        "# Пример списка файлов\n",
        "files = [\"file1.txt\", \"file2.txt\", \"file3.txt\"]\n",
        "process_files_threading(files)\n",
        "```\n",
        "\n",
        "**Почему потоки эффективны?**\n",
        "- Чтение файлов — это I/O-bound задача. Потоки могут освобождать GIL во время операций чтения, позволяя другим потокам выполняться параллельно.\n",
        "\n",
        "---\n",
        "\n",
        "#### Подход с процессами (неэффективен)\n",
        "\n",
        "Если мы попробуем использовать процессы для той же задачи, это создаст накладные расходы на создание процессов, так как чтение файлов не требует интенсивных вычислений.\n",
        "\n",
        "```python\n",
        "from multiprocessing import Process\n",
        "\n",
        "def count_words_in_file_process(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        content = f.read()\n",
        "    word_count = len(content.split())\n",
        "    print(f\"Файл {filename}: {word_count} слов\")\n",
        "\n",
        "def process_files_multiprocessing(file_list):\n",
        "    processes = [Process(target=count_words_in_file_process, args=(file,)) for file in file_list]\n",
        "    for process in processes:\n",
        "        process.start()\n",
        "    for process in processes:\n",
        "        process.join()\n",
        "\n",
        "process_files_multiprocessing(files)\n",
        "```\n",
        "\n",
        "**Почему процессы неэффективны?**\n",
        "- Создание процесса тяжелее, чем потока, и занимает больше времени.\n",
        "- Для I/O-bound задач потоки лучше, так как они используют общую память.\n",
        "\n",
        "---\n",
        "\n",
        "### Пример 2: Сетевые запросы к API\n",
        "\n",
        "**Задача**: Получить данные из нескольких API и сохранить результаты в файл.\n",
        "\n",
        "#### Подход с потоками\n",
        "\n",
        "```python\n",
        "import threading\n",
        "import requests\n",
        "\n",
        "def fetch_api(url):\n",
        "    response = requests.get(url)\n",
        "    print(f\"Данные с {url} получены: {len(response.text)} символов\")\n",
        "\n",
        "def process_urls_threading(url_list):\n",
        "    threads = [threading.Thread(target=fetch_api, args=(url,)) for url in url_list]\n",
        "    for thread in threads:\n",
        "        thread.start()\n",
        "    for thread in threads:\n",
        "        thread.join()\n",
        "\n",
        "urls = [\"https://example.com\", \"https://httpbin.org/get\", \"https://api.github.com\"]\n",
        "process_urls_threading(urls)\n",
        "```\n",
        "\n",
        "**Почему потоки эффективны?**\n",
        "- Сетевые запросы — это I/O-bound задача. Потоки позволяют выполнять несколько запросов одновременно, освобождая GIL во время ожидания ответа.\n",
        "\n",
        "#### Подход с процессами (неэффективен)\n",
        "\n",
        "Использование процессов для сетевых запросов будет менее эффективно, так как накладные расходы на создание процессов превышают выгоду от параллельности.\n",
        "\n",
        "---\n",
        "\n",
        "### Пример 3: Вычисление факториала для больших чисел\n",
        "\n",
        "**Задача**: Вычислить факториалы для нескольких больших чисел. Это CPU-bound задача, требующая интенсивных вычислений.\n",
        "\n",
        "#### Подход с потоками (неэффективен из-за GIL)\n",
        "\n",
        "```python\n",
        "import threading\n",
        "import math\n",
        "\n",
        "def calculate_factorial(n):\n",
        "    print(f\"Факториал {n} начал вычисляться\")\n",
        "    result = math.factorial(n)\n",
        "    print(f\"Факториал {n} вычислен\")\n",
        "\n",
        "numbers = [100000, 200000, 300000]\n",
        "threads = [threading.Thread(target=calculate_factorial, args=(num,)) for num in numbers]\n",
        "\n",
        "for thread in threads:\n",
        "    thread.start()\n",
        "for thread in threads:\n",
        "    thread.join()\n",
        "```\n",
        "\n",
        "**Почему потоки неэффективны?**\n",
        "- GIL ограничивает одновременное выполнение потоков для CPU-bound задач. Только один поток будет выполняться в каждый момент времени, что лишает программу преимущества многопоточности.\n",
        "\n",
        "#### Подход с процессами (эффективен)\n",
        "\n",
        "```python\n",
        "from multiprocessing import Process\n",
        "import math\n",
        "\n",
        "def calculate_factorial_process(n):\n",
        "    print(f\"Факториал {n} начал вычисляться\")\n",
        "    result = math.factorial(n)\n",
        "    print(f\"Факториал {n} вычислен\")\n",
        "\n",
        "processes = [Process(target=calculate_factorial_process, args=(num,)) for num in numbers]\n",
        "\n",
        "for process in processes:\n",
        "    process.start()\n",
        "for process in processes:\n",
        "    process.join()\n",
        "```\n",
        "\n",
        "**Почему процессы эффективны?**\n",
        "- Каждый процесс имеет свой интерпретатор Python, обходя GIL. Процессы выполняются параллельно на нескольких ядрах.\n",
        "\n",
        "---\n",
        "\n",
        "### Пример 4: Обработка изображений\n",
        "\n",
        "**Задача**: Преобразовать изображения (например, уменьшить размер) в большом количестве файлов.\n",
        "\n",
        "#### Подход с потоками\n",
        "\n",
        "```python\n",
        "from PIL import Image\n",
        "import threading\n",
        "\n",
        "def resize_image(filename):\n",
        "    with Image.open(filename) as img:\n",
        "        img = img.resize((100, 100))\n",
        "        img.save(f\"resized_{filename}\")\n",
        "        print(f\"{filename} обработано\")\n",
        "\n",
        "image_files = [\"image1.jpg\", \"image2.jpg\", \"image3.jpg\"]\n",
        "threads = [threading.Thread(target=resize_image, args=(img,)) for img in image_files]\n",
        "\n",
        "for thread in threads:\n",
        "    thread.start()\n",
        "for thread in threads:\n",
        "    thread.join()\n",
        "```\n",
        "\n",
        "**Когда потоки хороши?**\n",
        "- Если операции с изображениями включают чтение/запись файлов (I/O-bound), потоки могут быть полезны.\n",
        "\n",
        "#### Подход с процессами (эффективнее для CPU-bound)\n",
        "\n",
        "Если задачи с изображениями требуют интенсивных вычислений (например, применение фильтров или преобразований), процессы будут более эффективны:\n",
        "\n",
        "```python\n",
        "from multiprocessing import Pool\n",
        "from PIL import Image\n",
        "\n",
        "def resize_image_process(filename):\n",
        "    with Image.open(filename) as img:\n",
        "        img = img.resize((100, 100))\n",
        "        img.save(f\"resized_{filename}\")\n",
        "        print(f\"{filename} обработано\")\n",
        "\n",
        "with Pool(4) as pool:\n",
        "    pool.map(resize_image_process, image_files)\n",
        "```\n",
        "\n",
        "**Почему процессы лучше?**\n",
        "- Обработка изображений включает CPU-bound задачи (например, изменение пикселей), которые выполняются быстрее в процессах, так как они обходят GIL.\n",
        "\n",
        "---\n",
        "\n",
        "### Сравнение подходов\n",
        "\n",
        "| **Тип задачи**               | **Потоки**                              | **Процессы**                            |\n",
        "|-------------------------------|------------------------------------------|------------------------------------------|\n",
        "| **I/O-bound (чтение/запись)** | Эффективны                              | Менее эффективны                         |\n",
        "| **CPU-bound (вычисления)**    | Неэффективны из-за GIL                  | Эффективны, так как обходят GIL          |\n",
        "| **Накладные расходы**         | Легковесны                              | Тяжелее, из-за необходимости создания    |\n",
        "| **Совместный доступ к памяти**| Удобен, так как память общая            | Требует явного обмена данными через Queue|\n",
        "\n",
        "---\n",
        "\n",
        "### Итог\n",
        "\n",
        "1. Используйте **потоки для I/O-bound задач**, таких как чтение/запись файлов, сетевые запросы.\n",
        "2. Используйте **процессы для CPU-bound задач**, таких как сложные вычисления, обработка изображений.\n",
        "3. **Гибкость**: Для смешанных задач можно комбинировать процессы и потоки.\n",
        "4. **Понимание GIL**: GIL ограничивает параллельность в потоках для CPU-bound задач, но не влияет на процессы."
      ],
      "metadata": {
        "id": "rDP2P-Pq6Tcy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Расширенный обзор инструментов для параллельного выполнения задач в Python\n"
      ],
      "metadata": {
        "id": "UTRirtrGFDQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. **`concurrent.futures` и `ThreadPoolExecutor`/`ProcessPoolExecutor`**"
      ],
      "metadata": {
        "id": "_qigfu-nFMKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Модуль `concurrent.futures` предоставляет высокоуровневый интерфейс для работы с потоками и процессами.\n",
        "\n",
        "- **`ThreadPoolExecutor`**:\n",
        "  - Использует потоки для параллельного выполнения задач.\n",
        "  - Подходит для **I/O-bound задач**, например, чтения файлов или выполнения сетевых запросов.\n",
        "\n",
        "- **`ProcessPoolExecutor`**:\n",
        "  - Использует процессы для выполнения задач.\n",
        "  - Подходит для **CPU-bound задач**, например, сложных вычислений или обработки данных.\n",
        "\n",
        "**Пример с `ThreadPoolExecutor`**\n",
        "\n",
        "Чтение нескольких файлов параллельно:"
      ],
      "metadata": {
        "id": "bK3NzjrMFDL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import os\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        content = f.read()\n",
        "    print(f\"Файл {filename} прочитан\")\n",
        "    return len(content)\n",
        "\n",
        "files = ['file1.txt', 'file2.txt', 'file3.txt']\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=3) as executor:\n",
        "    results = list(executor.map(read_file, files))\n",
        "\n",
        "print(f\"Количество символов: {results}\")"
      ],
      "metadata": {
        "id": "vgkA7CEgFPfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Что происходит:**\n",
        "- Каждый файл читается в отдельном потоке.\n",
        "- `executor.map` автоматически распределяет задачи между потоками.\n",
        "\n",
        "**Пример с `ProcessPoolExecutor`**\n",
        "\n",
        "Вычисление факториалов больших чисел:"
      ],
      "metadata": {
        "id": "WScNiDINFDEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import math\n",
        "\n",
        "def calculate_factorial(n):\n",
        "    print(f\"Вычисляю факториал для {n}\")\n",
        "    return math.factorial(n)\n",
        "\n",
        "numbers = [100000, 200000, 300000]\n",
        "\n",
        "with ProcessPoolExecutor(max_workers=3) as executor:\n",
        "    results = list(executor.map(calculate_factorial, numbers))\n",
        "\n",
        "print(f\"Результаты: {[len(str(res)) for res in results]} цифр\")"
      ],
      "metadata": {
        "id": "XFr3GoMRFWG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Что происходит:**\n",
        "- Каждый процесс вычисляет факториал независимо.\n",
        "- Используются отдельные процессы, что позволяет обойти GIL."
      ],
      "metadata": {
        "id": "Xz3U1_4zFV-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. **Модуль `multiprocessing`**"
      ],
      "metadata": {
        "id": "YpiAJhUpFcby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модуль `multiprocessing` предоставляет инструменты для работы с процессами. Это низкоуровневый механизм по сравнению с `concurrent.futures`.\n",
        "\n",
        "**Основные элементы `multiprocessing`**\n",
        "\n",
        "1. **`Process`** — для создания и запуска отдельных процессов."
      ],
      "metadata": {
        "id": "yJDRTquVFcSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process\n",
        "\n",
        "def task(name):\n",
        "    print(f\"Процесс {name} начал выполнение\")\n",
        "\n",
        "processes = [Process(target=task, args=(i,)) for i in range(3)]\n",
        "\n",
        "for p in processes:\n",
        "    p.start()\n",
        "for p in processes:\n",
        "    p.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rExfpXJTFhso",
        "outputId": "5ae13b0e-1df7-491d-e2da-9b5e183e8b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Процесс 0 начал выполнение\n",
            "Процесс 1 начал выполнение\n",
            "Процесс 2 начал выполнение\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **`Pool`** — для создания пула процессов.\n"
      ],
      "metadata": {
        "id": "VVvty3dOFhfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "def square(x):\n",
        "    return x * x\n",
        "\n",
        "numbers = [1, 2, 3, 4, 5]\n",
        "\n",
        "with Pool(4) as pool:\n",
        "    results = pool.map(square, numbers)\n",
        "\n",
        "print(f\"Квадраты чисел: {results}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QkEnXVpFlL2",
        "outputId": "287ccc63-712a-4f13-a823-16d436839adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Квадраты чисел: [1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Очереди и каналы**\n",
        "\n",
        "Для обмена данными между процессами используются очереди и каналы."
      ],
      "metadata": {
        "id": "EWRo0lDJFk9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Queue\n",
        "\n",
        "def producer(queue):\n",
        "    for i in range(5):\n",
        "        queue.put(i)\n",
        "        print(f\"Производитель добавил {i}\")\n",
        "\n",
        "def consumer(queue):\n",
        "    while not queue.empty():\n",
        "        item = queue.get()\n",
        "        print(f\"Потребитель взял {item}\")\n",
        "\n",
        "queue = Queue()\n",
        "p1 = Process(target=producer, args=(queue,))\n",
        "p2 = Process(target=consumer, args=(queue,))\n",
        "\n",
        "p1.start()\n",
        "p1.join()\n",
        "p2.start()\n",
        "p2.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe29T2nFFopp",
        "outputId": "b5e00a22-7c08-4c6c-9c9f-909b436ff914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Производитель добавил 0\n",
            "Производитель добавил 1\n",
            "Производитель добавил 2\n",
            "Производитель добавил 3\n",
            "Производитель добавил 4\n",
            "Потребитель взял 0\n",
            "Потребитель взял 1\n",
            "Потребитель взял 2\n",
            "Потребитель взял 3\n",
            "Потребитель взял 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Канал:"
      ],
      "metadata": {
        "id": "8excoQB9FoNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Pipe\n",
        "\n",
        "def sender(pipe):\n",
        "    pipe.send(\"Сообщение из отправителя\")\n",
        "\n",
        "def receiver(pipe):\n",
        "    message = pipe.recv()\n",
        "    print(f\"Получено сообщение: {message}\")\n",
        "\n",
        "parent_conn, child_conn = Pipe()\n",
        "\n",
        "p1 = Process(target=sender, args=(child_conn,))\n",
        "p2 = Process(target=receiver, args=(parent_conn,))\n",
        "\n",
        "p1.start()\n",
        "p1.join()\n",
        "p2.start()\n",
        "p2.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQJRIv_WFw7B",
        "outputId": "1304b9a0-cdad-4358-de4f-f3f398b1cfe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Получено сообщение: Сообщение из отправителя\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. **`multiprocessing.dummy`**"
      ],
      "metadata": {
        "id": "1eDhP0pOFxHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модуль `multiprocessing.dummy` предоставляет интерфейс `multiprocessing`, но работает с потоками, а не процессами. Это полезно для задач, где нужна простота `multiprocessing`, но потоки предпочтительнее процессов.\n"
      ],
      "metadata": {
        "id": "K-MSRtZqF9r1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing.dummy import Pool\n",
        "\n",
        "def fetch_url(url):\n",
        "    import requests\n",
        "    response = requests.get(url)\n",
        "    return len(response.text)\n",
        "\n",
        "urls = ['https://example.com', 'https://httpbin.org/get', 'https://api.github.com']\n",
        "\n",
        "with Pool(4) as pool:\n",
        "    results = pool.map(fetch_url, urls)\n",
        "\n",
        "print(f\"Размеры ответов: {results}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlyFiUgGF7hY",
        "outputId": "ed824ecb-c1e6-42bc-9b43-56447537b37f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размеры ответов: [1256, 307, 2396]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Когда использовать?**\n",
        "- Для **I/O-bound задач** (например, сетевых запросов) с упрощенным интерфейсом `multiprocessing`."
      ],
      "metadata": {
        "id": "GXpovbxUF7un"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. **Сравнение инструментов**\n"
      ],
      "metadata": {
        "id": "dnZjPoCgGCnS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Инструмент                     | Используется для        | Особенности                                                                                      |\n",
        "|--------------------------------|-------------------------|--------------------------------------------------------------------------------------------------|\n",
        "| `ThreadPoolExecutor`           | I/O-bound задач         | Легковесные, используются потоки, конкурируют за GIL                                            |\n",
        "| `ProcessPoolExecutor`          | CPU-bound задач         | Использует процессы, обходит GIL, подходит для тяжелых вычислений                               |\n",
        "| `multiprocessing.Process`      | Ручное управление       | Полный контроль над процессами, требуется синхронизация                                         |\n",
        "| `multiprocessing.Pool`         | CPU-bound задач         | Упрощает распараллеливание задач, но с накладными расходами на обмен данными                   |\n",
        "| `multiprocessing.Queue`        | Обмен данными           | Очередь для безопасного взаимодействия между процессами                                         |\n",
        "| `multiprocessing.dummy.Pool`   | I/O-bound задач         | Аналог пула процессов, но использует потоки, подходит для сетевых запросов     "
      ],
      "metadata": {
        "id": "HOHPfkUtGCic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. **Пример комбинированного подхода**\n"
      ],
      "metadata": {
        "id": "lUqnHZISGJqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
        "\n",
        "# Функция для загрузки данных\n",
        "def fetch_data(url):\n",
        "    response = requests.get(url)\n",
        "    return response.text\n",
        "\n",
        "# Функция для обработки данных\n",
        "def process_data(data):\n",
        "    return len(data)\n",
        "\n",
        "urls = ['https://example.com', 'https://httpbin.org/get', 'https://api.github.com']\n",
        "\n",
        "# Загрузка данных с помощью потоков\n",
        "with ThreadPoolExecutor(max_workers=3) as thread_executor:\n",
        "    raw_data = list(thread_executor.map(fetch_data, urls))\n",
        "\n",
        "# Обработка данных с помощью процессов\n",
        "with ProcessPoolExecutor(max_workers=3) as process_executor:\n",
        "    results = list(process_executor.map(process_data, raw_data))\n",
        "\n",
        "print(f\"Результаты обработки: {results}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zioUYPIuGK5R",
        "outputId": "fb6a3281-5fb3-4a93-a629-ef6f503a5f21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результаты обработки: [1256, 307, 2262]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Почему это эффективно?**\n",
        "- Потоки эффективно обрабатывают I/O-bound задачи (загрузка данных).\n",
        "- Процессы обрабатывают CPU-bound задачи (анализ данных)."
      ],
      "metadata": {
        "id": "sAGj6JqOGJkr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ускорение работы с DataFrame с использованием параллельности\n"
      ],
      "metadata": {
        "id": "nM3LWp4pGaEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Библиотеки для ускорения работы с `DataFrame`\n"
      ],
      "metadata": {
        "id": "uG_1tke8GnzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **`pandas` с многопроцессностью (`multiprocessing`)**\n",
        "   - Использует стандартный `pandas`, распараллеливая операции по строкам или столбцам с помощью `multiprocessing`.\n",
        "\n",
        "2. **`modin`**\n",
        "   - Альтернатива `pandas`, автоматически распараллеливающая операции с использованием `Ray` или `Dask`.\n",
        "\n",
        "3. **`polars`**\n",
        "   - Высокопроизводительная библиотека для обработки данных с помощью многопоточности и оптимизаций на уровне алгоритмов."
      ],
      "metadata": {
        "id": "mSdmBaONGsSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Генерация большого DataFrame\n",
        "N_ROWS = 10**6\n",
        "df = pd.DataFrame({\n",
        "    'col1': np.random.randint(0, 100, N_ROWS),\n",
        "    'col2': np.random.rand(N_ROWS),\n",
        "    'col3': np.random.randint(0, 50, N_ROWS)\n",
        "})"
      ],
      "metadata": {
        "id": "kUaQYhNIGqwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. `pandas` + `multiprocessing`"
      ],
      "metadata": {
        "id": "4RTeoC5oGnvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "# Функция для обработки одной части DataFrame\n",
        "def process_chunk(chunk):\n",
        "    chunk['result'] = chunk['col1'] * chunk['col2'] + chunk['col3']\n",
        "    return chunk\n",
        "\n",
        "# Разделение DataFrame на части\n",
        "def parallel_apply(df, func, n_cores=4):\n",
        "    chunk_size = len(df) // n_cores\n",
        "    chunks = [df[i * chunk_size:(i + 1) * chunk_size] for i in range(n_cores)]\n",
        "\n",
        "    with Pool(n_cores) as pool:\n",
        "        results = pool.map(func, chunks)\n",
        "\n",
        "    return pd.concat(results)\n",
        "\n",
        "# Применение функции параллельно\n",
        "result_df = parallel_apply(df, process_chunk, n_cores=4)"
      ],
      "metadata": {
        "id": "6xPs7WibGwfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Как это работает:**\n",
        "- `multiprocessing` разделяет `DataFrame` на равные части.\n",
        "- Каждый процесс обрабатывает свой кусок данных.\n",
        "- Результаты объединяются в итоговый `DataFrame`."
      ],
      "metadata": {
        "id": "oUL-Hwo9Gwto"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. `modin`\n"
      ],
      "metadata": {
        "id": "URBPtIM7HOr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install \"modin[dask]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d8sUzbdHUWw",
        "outputId": "a30b023c-df05-430a-813c-5ad6fad1c868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: modin[dask] in /usr/local/lib/python3.10/dist-packages (0.32.0)\n",
            "Requirement already satisfied: pandas<2.3,>=2.2 in /usr/local/lib/python3.10/dist-packages (from modin[dask]) (2.2.2)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from modin[dask]) (24.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from modin[dask]) (1.26.4)\n",
            "Requirement already satisfied: fsspec>=2022.11.0 in /usr/local/lib/python3.10/dist-packages (from modin[dask]) (2024.10.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from modin[dask]) (5.9.5)\n",
            "Requirement already satisfied: dask>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from modin[dask]) (2024.11.2)\n",
            "Requirement already satisfied: distributed>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from modin[dask]) (2024.11.2)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask>=2.22.0->modin[dask]) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2.22.0->modin[dask]) (3.1.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2.22.0->modin[dask]) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask>=2.22.0->modin[dask]) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2.22.0->modin[dask]) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2.22.0->modin[dask]) (8.5.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.22.0->modin[dask]) (3.1.4)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.22.0->modin[dask]) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.22.0->modin[dask]) (1.1.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.22.0->modin[dask]) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.22.0->modin[dask]) (3.0.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.22.0->modin[dask]) (6.3.3)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.22.0->modin[dask]) (2.2.3)\n",
            "Requirement already satisfied: zict>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.22.0->modin[dask]) (3.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3,>=2.2->modin[dask]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3,>=2.2->modin[dask]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3,>=2.2->modin[dask]) (2024.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask>=2.22.0->modin[dask]) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed>=2.22.0->modin[dask]) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.3,>=2.2->modin[dask]) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import modin.pandas as mpd\n",
        "\n",
        "# Преобразование pandas DataFrame в modin DataFrame\n",
        "modin_df = mpd.DataFrame(df)\n",
        "\n",
        "# Выполнение вычислений\n",
        "modin_df['result'] = modin_df['col1'] * modin_df['col2'] + modin_df['col3']"
      ],
      "metadata": {
        "id": "oCAdoyzxHQ01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Как это работает:**\n",
        "- `modin` автоматически оптимизирует операции с помощью `Ray` или `Dask`.\n",
        "- Используется тот же синтаксис, что и у `pandas`, что делает переход простым."
      ],
      "metadata": {
        "id": "7Le1NTjvHOnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. `polars`"
      ],
      "metadata": {
        "id": "n22i-WWtHa4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "\n",
        "# Преобразование pandas DataFrame в polars DataFrame\n",
        "polars_df = pl.from_pandas(df)\n",
        "\n",
        "# Выполнение вычислений\n",
        "polars_df = polars_df.with_columns((pl.col(\"col1\") * pl.col(\"col2\") + pl.col(\"col3\")).alias(\"result\"))"
      ],
      "metadata": {
        "id": "Kg8eVVuKHq0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Как это работает:**\n",
        "- `polars` использует многопоточность и оптимизированные алгоритмы для обработки данных.\n",
        "- Интерфейс отличается от `pandas`, но предоставляет высокую производительность.\n"
      ],
      "metadata": {
        "id": "JY4eWu9WHOfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. `joblib`"
      ],
      "metadata": {
        "id": "DN2p7_QqQ4QL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import Parallel, delayed\n",
        "\n",
        "# Обработка частей DataFrame\n",
        "def process_chunk(chunk):\n",
        "    chunk['result'] = chunk['col1'] * chunk['col2'] + chunk['col3']\n",
        "    return chunk\n",
        "\n",
        "# Распараллеливание по частям DataFrame\n",
        "def parallel_apply_chunks(df, func, n_jobs=4):\n",
        "    chunks = np.array_split(df, n_jobs)\n",
        "    results = Parallel(n_jobs=n_jobs)(delayed(func)(chunk) for chunk in chunks)\n",
        "    return pd.concat(results)\n"
      ],
      "metadata": {
        "id": "tfS9qxKuQ4QL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **`Parallel`**: выполняет параллельные задачи, распределяя их между потоками или процессами.\n",
        "- **`delayed`**: позволяет определить, какие функции и аргументы будут параллельно переданы в `Parallel`.\n",
        "\n",
        "`joblib` работает с `loky`, `multiprocessing` или `threading` в зависимости от типа задачи (CPU-bound или I/O-bound). Она автоматически выбирает оптимальный бэкенд, но это можно настроить вручную."
      ],
      "metadata": {
        "id": "w4qaOhE7Q4QL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Бенчмарк\n"
      ],
      "metadata": {
        "id": "rOoqxK6_Hwfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Функция для измерения времени выполнения\n",
        "def benchmark(func, *args, **kwargs):\n",
        "    start_time = time.time()\n",
        "    result = func(*args, **kwargs)\n",
        "    end_time = time.time()\n",
        "    print(f\"{func.__name__} выполнено за {end_time - start_time:.2f} секунд\")\n",
        "    return result\n",
        "\n",
        "# Тестовые функции\n",
        "def test_pandas_multiprocessing():\n",
        "    return parallel_apply(df, process_chunk, n_cores=4)\n",
        "\n",
        "def test_modin():\n",
        "    modin_df = mpd.DataFrame(df)\n",
        "    modin_df['result'] = modin_df['col1'] * modin_df['col2'] + modin_df['col3']\n",
        "    return modin_df\n",
        "\n",
        "def test_polars():\n",
        "    polars_df = pl.from_pandas(df)\n",
        "    return polars_df.with_columns((pl.col(\"col1\") * pl.col(\"col2\") + pl.col(\"col3\")).alias(\"result\"))\n",
        "\n",
        "# Запуск бенчмарка\n",
        "benchmark(test_pandas_multiprocessing)\n",
        "benchmark(test_modin)\n",
        "benchmark(test_polars)\n",
        "benchmark(parallel_apply_chunks, df, process_row, 4)\n",
        "pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "j1b1eq9cHw0z",
        "outputId": "4be3b616-38d4-4538-ecf7-fa9d9ec46fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_pandas_multiprocessing выполнено за 0.54 секунд\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UserWarning: Sending large graph of size 30.52 MiB.\n",
            "This may cause some slowdown.\n",
            "Consider loading the data with Dask directly\n",
            " or using futures or delayed objects to embed the data into the graph without repetition.\n",
            "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-6a9f2c79f3ac>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Запуск бенчмарка\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pandas_multiprocessing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mbenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_modin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_polars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-6a9f2c79f3ac>\u001b[0m in \u001b[0;36mbenchmark\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{func.__name__} выполнено за {end_time - start_time:.2f} секунд\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-6a9f2c79f3ac>\u001b[0m in \u001b[0;36mtest_dask\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdask_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdask_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdask_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_partitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'col1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'col2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'col3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdask_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_modin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask_expr/_collection.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, fuse, concatenate, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfuse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDaskMethodsMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \"\"\"\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mshorten_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Подход                   | Время выполнения | Преимущества                                     | Недостатки                      |\n",
        "|--------------------------|------------------|-------------------------------------------------|---------------------------------|\n",
        "| `pandas + multiprocessing` | Среднее          | Гибкость, используется стандартный `pandas`     | Высокие накладные расходы       |\n",
        "| `modin`                  | Высокое          | Совместимость с `pandas`, простота использования | Зависимость от `Ray` или `Dask` |\n",
        "| `polars`                 | Очень высокое    | Отличная производительность, многопоточность   | Требует изучения нового API     |\n"
      ],
      "metadata": {
        "id": "6FPsR3ExHwYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Как работают `Polars` и `Dask`: Внутренние механизмы и оптимизации\n",
        "\n",
        "**`Polars`**\n",
        "\n",
        "`Polars` — это современная библиотека для обработки данных, которая написана на **Rust**, известном своей высокой производительностью. Она спроектирована для работы с данными в колонковом формате, аналогично базам данных OLAP (Online Analytical Processing).\n",
        "\n",
        "**Основные принципы работы**\n",
        "\n",
        "1. **Поколоночное хранение данных (Columnar Storage)**\n",
        "   - В отличие от `pandas`, где данные хранятся в строковом формате, `Polars` организует данные в **поколоночном формате**.\n",
        "   - Это позволяет эффективно использовать кэш процессора, так как операции над данными выполняются над целыми колонками, а не строками.\n",
        "\n",
        "2. **Многопоточность**\n",
        "   - `Polars` активно использует многопоточность для выполнения операций. Это позволяет эффективно использовать все доступные ядра процессора.\n",
        "   - Например, если нужно выполнить операцию над всей колонкой, `Polars` разбивает её на части и обрабатывает их параллельно.\n",
        "\n",
        "3. **Память на уровне языка Rust**\n",
        "   - Rust обеспечивает безопасность работы с памятью и низкий уровень накладных расходов.\n",
        "   - Благодаря Rust, `Polars` может эффективно управлять ресурсами, минимизируя выделение и освобождение памяти.\n",
        "\n",
        "4. **Оптимизированные вычисления**\n",
        "   - Использует векторизированные вычисления, где операции выполняются сразу над блоками данных.\n",
        "   - Пример: вместо того чтобы проходить по колонке элемент за элементом, `Polars` выполняет операцию над группами элементов, используя SIMD (Single Instruction, Multiple Data).\n",
        "\n",
        "#### Пример оптимизации в `Polars`:\n",
        "- Для выполнения операции, такой как `(col1 * col2) + col3`, `Polars` создает **физический план выполнения**. Этот план оптимизируется, чтобы минимизировать количество операций.\n",
        "- Пример: если `col1` и `col2` уже загружены в кэш, их произведение выполняется быстрее.\n",
        "\n",
        "---\n",
        "\n",
        "**`Dask`**\n",
        "\n",
        "`Dask` — это библиотека, которая расширяет `pandas`, позволяя работать с большими данными и распределенными вычислениями. В отличие от `Polars`, `Dask` сосредоточен на работе с **большими объемами данных**, которые могут не помещаться в оперативную память.\n",
        "\n",
        "**Основные принципы работы**\n",
        "\n",
        "1. **Разделение данных на части (Partitions)**\n",
        "   - `Dask` делит данные на **маленькие разделы** (partitions), которые могут быть обработаны независимо.\n",
        "   - Например, если у вас есть DataFrame из 1 миллиарда строк, `Dask` разбивает его на 100 частей по 10 миллионов строк каждая.\n",
        "\n",
        "2. **Граф задач (Task Graph)**\n",
        "   - `Dask` создает **граф задач**, описывающий, как операции связаны друг с другом.\n",
        "   - Каждая операция выполняется только тогда, когда она действительно требуется (ленивое выполнение).\n",
        "   - Пример: при вычислении средней температуры `Dask` сначала рассчитывает сумму и количество строк для каждой части, а затем агрегирует результаты.\n",
        "\n",
        "3. **Многопоточность и многопроцессность**\n",
        "   - `Dask` может использовать как потоки, так и процессы для выполнения операций параллельно.\n",
        "   - Например, при работе на локальной машине он использует потоки, а в кластере — распределенные процессы.\n",
        "\n",
        "4. **Распределенные вычисления**\n",
        "   - Если объем данных слишком велик для одной машины, `Dask` может использовать кластер серверов.\n",
        "   - Каждый сервер обрабатывает свою часть данных, а результаты объединяются.\n",
        "\n",
        "5. **Интеграция с `NumPy` и `pandas`**\n",
        "   - `Dask` использует знакомый интерфейс `pandas` и `NumPy`, что упрощает переход.\n",
        "   - Это также позволяет использовать оптимизации, доступные в этих библиотеках.\n",
        "\n",
        "#### Пример оптимизации в `Dask`:\n",
        "- Если вы вычисляете сумму по всей таблице, `Dask` сначала вычисляет суммы для каждого раздела, а затем объединяет их. Это экономит память и снижает нагрузку на процессор.\n",
        "\n",
        "| **Особенность**                  | **Polars**                                      | **Dask**                                       |\n",
        "|----------------------------------|------------------------------------------------|-----------------------------------------------|\n",
        "| **Обработка больших данных**     | Ориентирован на данные, которые помещаются в память | Спроектирован для работы с данными, которые не помещаются в память |\n",
        "| **Подход к параллельности**      | Многопоточность на уровне одного узла          | Поддержка многопоточности и многопроцессности, включая кластеры |\n",
        "| **Формат хранения данных**       | Колонковое                                     | Табличное (строковое), аналогично `pandas`    |\n",
        "| **Оптимизации**                  | Векторизация, SIMD, оптимизированное планирование | Разделение задач, ленивое выполнение          |\n",
        "| **Гибкость**                     | Меньше возможностей для работы с произвольными форматами данных | Высокая гибкость для обработки произвольных данных |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "BeSUdSEIIsaQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Комбинирование асинхронности и многопоточности"
      ],
      "metadata": {
        "id": "sST1YJbw5h-0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Комбинирование асинхронности и многопоточности в Python может дать значительные преимущества в ситуациях, когда в приложении используются разные типы задач — например, асинхронные операции ввода-вывода (сетевые запросы, работа с базой данных) и вычислительно интенсивные задачи, которые требуют выполнения параллельно.\n",
        "\n",
        "### Когда комбинирование асинхронности и многопоточности полезно\n",
        "\n",
        "1. **Интенсивные CPU-bound задачи с асинхронным управлением**:\n",
        "   - Асинхронность сама по себе отлично работает для I/O-bound задач (сетевые запросы, работа с файлами), но менее эффективна для CPU-bound задач из-за GIL (Global Interpreter Lock). Многопоточность позволяет параллельно выполнять вычислительные задачи, обходя GIL.\n",
        "\n",
        "2. **Асинхронное приложение с потребностью в параллельных вычислениях**:\n",
        "   - Например, веб-сервер, который обслуживает множество запросов пользователей и одновременно выполняет тяжелые задачи, такие как обработка данных, сжатие изображений, преобразование видео и т. д. В таких случаях полезно организовать обработку запросов асинхронно, а тяжелые вычисления делегировать потокам.\n",
        "\n",
        "3. **Интеграция с блокирующими API**:\n",
        "   - Некоторые библиотеки или внешние API имеют блокирующие вызовы. Многопоточность позволяет использовать эти библиотеки параллельно с асинхронными корутинами, чтобы избежать блокировки всего асинхронного цикла.\n",
        "\n",
        "### Как организовать комбинирование асинхронности и многопоточности\n",
        "\n",
        "В Python есть несколько инструментов, которые позволяют комбинировать асинхронность с многопоточностью. Основной подход — использование `asyncio` с `concurrent.futures.ThreadPoolExecutor`. Давайте разберем этот подход.\n",
        "\n",
        "#### Основные шаги для комбинирования\n",
        "\n",
        "1. **Использование `ThreadPoolExecutor` для выполнения CPU-bound задач**:\n",
        "   - Создайте пул потоков (`ThreadPoolExecutor`), чтобы делегировать вычислительно интенсивные задачи, которые будут выполняться параллельно, освобождая GIL.\n",
        "\n",
        "2. **Запуск блокирующих функций с помощью `run_in_executor`**:\n",
        "   - `asyncio.run_in_executor` позволяет запускать блокирующую функцию в пуле потоков, не блокируя основной асинхронный цикл.\n",
        "\n",
        "3. **Асинхронное ожидание результатов с `await`**:\n",
        "   - Вы можете асинхронно ожидать завершения потоков с помощью `await`, продолжая работу с другими асинхронными задачами.\n",
        "\n",
        "### Пример: Асинхронное приложение с использованием многопоточности\n",
        "\n",
        "Представим себе приложение, которое обрабатывает входящие сетевые запросы асинхронно, а для каждой задачи выполняет тяжелую вычислительную работу в отдельном потоке.\n",
        "\n",
        "```python\n",
        "import asyncio\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import time\n",
        "\n",
        "# Вычислительно интенсивная функция\n",
        "def cpu_bound_task(n):\n",
        "    print(f\"Начало вычисления для {n}\")\n",
        "    total = 0\n",
        "    for i in range(10**7):\n",
        "        total += i * n\n",
        "    print(f\"Завершено вычисление для {n}\")\n",
        "    return total\n",
        "\n",
        "# Асинхронная обертка для CPU-bound задачи\n",
        "async def run_cpu_task(executor, n):\n",
        "    # Запускаем CPU-bound задачу в пуле потоков\n",
        "    result = await asyncio.get_running_loop().run_in_executor(executor, cpu_bound_task, n)\n",
        "    print(f\"Результат для {n}: {result}\")\n",
        "\n",
        "# Основная асинхронная функция\n",
        "async def main():\n",
        "    # Создаем пул потоков с 4 потоками\n",
        "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "        # Запускаем несколько задач параллельно\n",
        "        tasks = [run_cpu_task(executor, i) for i in range(4)]\n",
        "        \n",
        "        # Ожидаем завершения всех задач\n",
        "        await asyncio.gather(*tasks)\n",
        "\n",
        "# Запуск основного цикла\n",
        "asyncio.run(main())\n",
        "```\n",
        "\n",
        "### Объяснение примера\n",
        "\n",
        "1. **CPU-bound функция** (`cpu_bound_task`):\n",
        "   - Это синхронная функция, выполняющая интенсивные вычисления (например, подсчет суммы для большого числа).\n",
        "   \n",
        "2. **Асинхронная обертка** (`run_cpu_task`):\n",
        "   - Оборачивает CPU-bound функцию в асинхронную корутину. С помощью `asyncio.get_running_loop().run_in_executor` передаем выполнение CPU-bound задачи в пул потоков, чтобы избежать блокировки основного асинхронного цикла.\n",
        "\n",
        "3. **Пул потоков** (`ThreadPoolExecutor`):\n",
        "   - Создаем пул с 4 потоками, который параллельно выполняет CPU-bound задачи.\n",
        "\n",
        "4. **Асинхронное ожидание результатов** (`await asyncio.gather(*tasks)`):\n",
        "   - С помощью `asyncio.gather` запускаем все задачи параллельно, ожидая их завершения. В это время основной цикл событий может выполнять другие корутины, если они есть.\n",
        "\n",
        "### Когда это дает профит\n",
        "\n",
        "1. **Смешанные I/O-bound и CPU-bound задачи**:\n",
        "   - Асинхронный код (корутины) обрабатывает сетевые запросы и другие задачи ввода-вывода, а пул потоков обрабатывает интенсивные вычислительные задачи. Это позволяет эффективно распределять нагрузку между асинхронными и параллельными задачами.\n",
        "\n",
        "2. **Минимизация времени ожидания**:\n",
        "   - `asyncio.run_in_executor` позволяет выполнять тяжелые задачи в потоках, не задерживая выполнение других асинхронных задач. Это полезно для приложений, где важна отзывчивость, например, веб-сервера.\n",
        "\n",
        "3. **Эффективное использование GIL**:\n",
        "   - Потоки Python не освобождают GIL для синхронных операций, но при I/O-bound и CPU-bound задачах параллельность позволяет снизить время блокировок GIL. Например, если несколько потоков выполняют задачи, требующие использования системных вызовов, GIL не блокирует их работу.\n",
        "\n",
        "### Советы по организации\n",
        "\n",
        "1. **Избегайте чрезмерного числа потоков**:\n",
        "   - Пул потоков `ThreadPoolExecutor` должен иметь ограниченное количество потоков, соответствующее ресурсам системы. Слишком много потоков могут снизить производительность из-за переключения контекста.\n",
        "\n",
        "2. **Грамотно используйте `run_in_executor`**:\n",
        "   - Этот метод следует применять только для действительно CPU-bound или блокирующих функций. Для простых функций `await` и `asyncio` вполне достаточно.\n",
        "\n",
        "3. **Рассмотрите `ProcessPoolExecutor` для тяжелых CPU-bound задач**:\n",
        "   - В случаях, где задачи действительно очень интенсивны, можно использовать `concurrent.futures.ProcessPoolExecutor`, который использует процессы, а не потоки, и позволяет обойти GIL, используя несколько ядер процессора.\n",
        "\n",
        "---\n",
        "\n",
        "### Продвинутый пример: Асинхронные сетевые запросы и вычисления\n",
        "\n",
        "Теперь представим пример, где у нас есть асинхронные сетевые запросы и тяжелая задача, которая выполняется в отдельном процессе для обхода GIL.\n",
        "\n",
        "```python\n",
        "import asyncio\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import aiohttp\n",
        "\n",
        "# CPU-bound задача для обработки данных\n",
        "def data_processing_task(data):\n",
        "    # Эмуляция тяжелого процесса\n",
        "    print(\"Начало обработки данных...\")\n",
        "    total = sum([ord(char) for char in data])  # Пример обработки\n",
        "    print(\"Обработка завершена.\")\n",
        "    return total\n",
        "\n",
        "# Асинхронная функция для сетевого запроса\n",
        "async def fetch_data(url):\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        async with session.get(url) as response:\n",
        "            data = await response.text()\n",
        "            print(f\"Получены данные с {url}\")\n",
        "            return data\n",
        "\n",
        "# Асинхронная функция для запуска задачи обработки данных в отдельном процессе\n",
        "async def process_data_in_executor(executor, data):\n",
        "    result = await asyncio.get_running_loop().run_in_executor(executor, data_processing_task, data)\n",
        "    print(f\"Результат обработки данных: {result}\")\n",
        "\n",
        "async def main():\n",
        "    url = \"https://www.example.com\"\n",
        "    \n",
        "    # Создаем процессный пул\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        # Запускаем асинхронный запрос\n",
        "        data = await fetch_data(url)\n",
        "        \n",
        "        # Запускаем обработку данных в отдельном процессе\n",
        "        await process_data_in_executor(executor, data)\n",
        "\n",
        "# Запуск основного цикла\n",
        "asyncio.run(main())\n",
        "```\n",
        "\n",
        "### Объяснение\n",
        "\n",
        "1. **Асинхронный сетевой запрос** (`fetch_data`):\n",
        "   - Использует `aiohttp` для асинхронного получения данных.\n",
        "\n",
        "2. **CPU-bound задача в процессе** (`data_processing_task`):\n",
        "   - Выполняет вычислительную операцию в отдельном процессе для обхода GIL.\n",
        "\n",
        "3. **Комбинация с ProcessPoolExecutor**:\n",
        "   - `ProcessPoolExecutor` используется вместо `ThreadPoolExecutor` для тяжелой задачи, поскольку процессы могут работать параллельно, используя несколько ядер процессора.\n"
      ],
      "metadata": {
        "id": "U1aX6jYU5h71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Комбинирование асинхронности и многопроцессности"
      ],
      "metadata": {
        "id": "52pwVPJ95h0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Комбинирование асинхронности и многопроцессности в Python может дать еще больший выигрыш в производительности, особенно в случаях, когда требуется одновременно управлять **I/O-bound** и **CPU-bound** задачами. В отличие от многопоточности, многопроцессность позволяет выполнять задачи **параллельно на уровне процессов**, что помогает обойти ограничение GIL (Global Interpreter Lock) в Python и использовать несколько ядер процессора.\n",
        "\n",
        "### Когда комбинирование асинхронности и многопроцессности полезно?\n",
        "\n",
        "1. **Смешанные I/O-bound и CPU-bound задачи**:\n",
        "   - Асинхронность идеально подходит для управления I/O-bound задачами, такими как сетевые запросы, чтение и запись файлов, а CPU-bound задачи лучше выполнять в отдельных процессах, чтобы они использовали несколько ядер.\n",
        "\n",
        "2. **Обработка тяжелых вычислительных задач в параллельных процессах**:\n",
        "   - Если приложение одновременно обрабатывает сетевые запросы и проводит вычисления (например, машинное обучение, сложные математические операции), многопроцессность позволяет выполнять вычисления параллельно без блокировки основного асинхронного цикла.\n",
        "\n",
        "3. **Обход GIL для CPU-bound задач**:\n",
        "   - GIL ограничивает производительность Python в многопоточном контексте, но многопроцессность позволяет обходить GIL, поскольку каждый процесс работает в своем интерпретаторе Python и может параллельно выполнять вычисления.\n",
        "\n",
        "### Как организовать многопроцессность с асинхронностью\n",
        "\n",
        "Основной способ интеграции многопроцессности с асинхронностью в Python — использование **ProcessPoolExecutor** из модуля `concurrent.futures`. С `ProcessPoolExecutor` можно запускать вычислительно интенсивные задачи в отдельных процессах и получать их результаты, не блокируя асинхронный цикл `asyncio`.\n",
        "\n",
        "### Пример: Асинхронное приложение с использованием многопроцессности\n",
        "\n",
        "Допустим, у нас есть асинхронное приложение, которое получает данные из API и обрабатывает их параллельно в нескольких процессах.\n",
        "\n",
        "```python\n",
        "import asyncio\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import aiohttp\n",
        "\n",
        "# Функция для CPU-bound задачи\n",
        "def process_data(data):\n",
        "    print(\"Начало обработки данных...\")\n",
        "    result = sum(ord(char) for char in data)  # Эмуляция тяжелой задачи\n",
        "    print(\"Обработка завершена.\")\n",
        "    return result\n",
        "\n",
        "# Асинхронная функция для получения данных из API\n",
        "async def fetch_data(url):\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        async with session.get(url) as response:\n",
        "            data = await response.text()\n",
        "            print(f\"Получены данные с {url}\")\n",
        "            return data\n",
        "\n",
        "# Асинхронная функция для запуска CPU-bound задачи в процессе\n",
        "async def run_cpu_task_in_executor(executor, data):\n",
        "    loop = asyncio.get_running_loop()\n",
        "    result = await loop.run_in_executor(executor, process_data, data)\n",
        "    print(f\"Результат обработки данных: {result}\")\n",
        "\n",
        "# Основная функция\n",
        "async def main():\n",
        "    url = \"https://www.example.com\"\n",
        "\n",
        "    # Создаем процессный пул с 4 процессами\n",
        "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
        "        # Получаем данные асинхронно\n",
        "        data = await fetch_data(url)\n",
        "        \n",
        "        # Обрабатываем данные в нескольких процессах\n",
        "        tasks = [run_cpu_task_in_executor(executor, data) for _ in range(4)]\n",
        "        \n",
        "        # Ожидаем завершения всех задач\n",
        "        await asyncio.gather(*tasks)\n",
        "\n",
        "# Запуск\n",
        "asyncio.run(main())\n",
        "```\n",
        "\n",
        "### Объяснение\n",
        "\n",
        "1. **Асинхронная I/O-bound задача** (`fetch_data`):\n",
        "   - Выполняет сетевой запрос к API асинхронно, используя `aiohttp`, что позволяет не блокировать основной цикл событий `asyncio`.\n",
        "\n",
        "2. **CPU-bound функция** (`process_data`):\n",
        "   - Выполняет тяжелую вычислительную задачу (например, подсчет суммы), которая может занимать значительное время. Поскольку это CPU-bound задача, она будет выполняться в отдельном процессе.\n",
        "\n",
        "3. **Асинхронный запуск CPU-bound задачи в процессе** (`run_cpu_task_in_executor`):\n",
        "   - Функция `run_cpu_task_in_executor` использует `loop.run_in_executor` с `ProcessPoolExecutor` для запуска CPU-bound задачи в отдельных процессах. Это позволяет выполнять задачу параллельно и освобождает основной цикл `asyncio`.\n",
        "\n",
        "4. **Процессный пул** (`ProcessPoolExecutor`):\n",
        "   - Мы создаем `ProcessPoolExecutor` с четырьмя процессами. Каждый процесс будет выполнять тяжелую задачу независимо, что позволяет одновременно обрабатывать несколько задач.\n",
        "\n",
        "### Когда это действительно дает профит\n",
        "\n",
        "1. **Обработка больших объемов данных**:\n",
        "   - Приложения, работающие с большим количеством данных (например, анализ текстов, машинное обучение), могут выполнять обработку в нескольких процессах, параллельно занимаясь получением данных асинхронно.\n",
        "\n",
        "2. **Обработка нескольких запросов одновременно**:\n",
        "   - Асинхронная обработка позволяет одновременно обрабатывать множество запросов, не ожидая завершения других задач.\n",
        "\n",
        "3. **Обход ограничений GIL**:\n",
        "   - Многопроцессность позволяет выполнять CPU-bound задачи в отдельных процессах, избегая ограничения GIL и эффективно используя все доступные ядра процессора.\n",
        "\n",
        "### Продвинутый пример: Асинхронные запросы и многопроцессная обработка\n",
        "\n",
        "Теперь представим пример, где данные асинхронно собираются с нескольких API, а затем обрабатываются в нескольких процессах.\n",
        "\n",
        "```python\n",
        "import asyncio\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import aiohttp\n",
        "\n",
        "# CPU-bound функция для обработки данных\n",
        "def process_data(data):\n",
        "    print(\"Начало обработки данных...\")\n",
        "    result = sum(ord(char) for char in data)  # Эмуляция обработки\n",
        "    print(\"Обработка завершена.\")\n",
        "    return result\n",
        "\n",
        "# Асинхронная функция для получения данных из API\n",
        "async def fetch_data(url):\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        async with session.get(url) as response:\n",
        "            data = await response.text()\n",
        "            print(f\"Получены данные с {url}\")\n",
        "            return data\n",
        "\n",
        "# Асинхронная функция для запуска CPU-bound задачи в процессе\n",
        "async def run_cpu_task_in_executor(executor, data):\n",
        "    loop = asyncio.get_running_loop()\n",
        "    result = await loop.run_in_executor(executor, process_data, data)\n",
        "    print(f\"Результат обработки данных: {result}\")\n",
        "\n",
        "async def main():\n",
        "    urls = [\n",
        "        \"https://www.example.com/page1\",\n",
        "        \"https://www.example.com/page2\",\n",
        "        \"https://www.example.com/page3\"\n",
        "    ]\n",
        "    \n",
        "    # Создаем процессный пул\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        # Асинхронно получаем данные из нескольких URL\n",
        "        fetch_tasks = [fetch_data(url) for url in urls]\n",
        "        fetched_data = await asyncio.gather(*fetch_tasks)\n",
        "        \n",
        "        # Обрабатываем полученные данные параллельно в нескольких процессах\n",
        "        process_tasks = [run_cpu_task_in_executor(executor, data) for data in fetched_data]\n",
        "        \n",
        "        # Ожидаем завершения всех задач\n",
        "        await asyncio.gather(*process_tasks)\n",
        "\n",
        "# Запуск программы\n",
        "asyncio.run(main())\n",
        "```\n",
        "\n",
        "- **Асинхронное получение данных**: `fetch_data` параллельно получает данные из нескольких API без блокировки основного цикла событий `asyncio`.\n",
        "- **Параллельная обработка данных**: После получения данных каждое из них обрабатывается в отдельном процессе, обходя GIL и эффективно используя процессорные ресурсы.\n",
        "- **Эффективность и масштабируемость**: Такой подход позволяет приложению одновременно обрабатывать множество сетевых запросов и выполнять вычислительные задачи, минимизируя время ожидания."
      ],
      "metadata": {
        "id": "MJpemAUN5v5e"
      }
    }
  ]
}